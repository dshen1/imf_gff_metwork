{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import community \n",
    "from itertools import compress\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from seaborn import color_palette, set_style, palplot\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export 2009 and 2015 data for gephi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. First, define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    keep_var = ['countrycode','counterpart_code','country','counterpart','year','CDIS_IAD','CPIS_IAP','loans_dep']\n",
    "    df = df[keep_var]                           ## keep only used variables \n",
    "    df = df.replace(np.nan,0)                   ## turn na to zero \n",
    "    num = df._get_numeric_data()\n",
    "    num[num < 0] = 0                            ## turn negative to zero \n",
    "    df['total'] = df[['CDIS_IAD','CPIS_IAP','loans_dep']].sum(axis=1)\n",
    "\n",
    "    mata = ['countrycode','counterpart_code','country','counterpart','year']\n",
    "    var_org = ['CDIS_IAD','CPIS_IAP','loans_dep','total']\n",
    "    var_sum_out = ['CDIS_Sum_out','CPIS_Sum_out','loans_dep_Sum_out','total_Sum_out']\n",
    "    var_sum_in = ['CDIS_Sum_in','CPIS_Sum_in','loans_dep_Sum_in','total_Sum_in']\n",
    "    var_weight = ['CDIS_weight','CPIS_weight','loans_dep_weight','total_weight']\n",
    "\n",
    "    df[var_sum_out]= df.groupby(['countrycode','year'])[var_org].transform(sum)           ## like stata egen sum \n",
    "    df[var_sum_in]= df.groupby(['counterpart_code','year'])[var_org].transform(sum)        ## like stata egen sum \n",
    "    df_weight = pd.DataFrame((df[var_org].values / df[var_sum_out].values)*100,columns=[var_weight])\n",
    "    df[var_weight] = df_weight                                                        ## create the weight variables \n",
    "    mata.extend(var_weight)\n",
    "    df = df[mata]\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def export_gephi(df,year,var):\n",
    "    ## clean the data first \n",
    "    df_y = df[df['year']==year]\n",
    "    df_y.fillna(0,inplace=True)\n",
    "    df_y = df_y[df_y[var]>0]\n",
    "    G = nx.from_pandas_dataframe(df_y, source=\"country\", target=\"counterpart\", edge_attr=[var],create_using=nx.DiGraph())\n",
    "    get_hierarchy_cluster(G,var)                                   ## add hierarchy_cluster to node attribute\n",
    "    get_nx_community(G,var)                                        ## add nx community detection to node attribute\n",
    "    get_eigen_centrality(G,var)\n",
    "    nx.write_gexf(G, \"../result/gexf/\"+var+str(year)+\".gexf\")\n",
    "    return G\n",
    "\n",
    "def get_hierarchy_cluster(G,var):\n",
    "    node_list = G.nodes()\n",
    "    node_list.sort()\n",
    "    A = nx.to_numpy_matrix(G = G,nodelist=node_list,weight=var)\n",
    "    M = pdist(A, 'cosine')                          # it will return a vector, this is using cosine distance\n",
    "    M = squareform(M)    \n",
    "    NaNs = np.isnan(M)\n",
    "    M[NaNs] = 1   \n",
    "    Z = hierarchy.average(M)\n",
    "    k=6\n",
    "    clusters = fcluster(Z, k, criterion='maxclust')                          ## one kind of auto cluster selection \n",
    "    hierarchy_cluster = {k: int(v)-1 for k, v in zip(node_list, clusters)}   ## make it start from 0 \n",
    "    nx.set_node_attributes(G, 'hierarchy_cluster', hierarchy_cluster)\n",
    "\n",
    "def get_nx_community(G,var):\n",
    "#algorism: https://sites.google.com/site/findcommunities/\n",
    "#package: http://perso.crans.org/aynaud/communities/\n",
    "    \n",
    "    ## use adj matrix + its invert, so the edge will be the sum of in and out edge weight \n",
    "    node_list = G.nodes()\n",
    "    node_list.sort()\n",
    "    A = nx.to_numpy_matrix(G = G,nodelist=node_list,weight=var)\n",
    "    ud_M = A + A.T \n",
    "    ud_G = nx.from_numpy_matrix(ud_M)\n",
    "    ## relable node to country name \n",
    "    maplist = dict(zip(ud_G.nodes(), node_list))\n",
    "    ud_G = nx.relabel_nodes(ud_G,maplist) \n",
    "    l_community = community.best_partition(ud_G,weight='weight',resolution=1)\n",
    "    nx.set_node_attributes(G, 'nx_community', l_community)\n",
    "    \n",
    "def get_eigen_centrality(G,var):\n",
    "        ## eigenvector centrality\n",
    "    e = nx.eigenvector_centrality_numpy(G,weight=var)\n",
    "    nx.set_node_attributes(G, 'eigenvector_centrality', e) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. read stata data and export it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read pre-processed data from stata\n",
    "df = pd.read_stata('../data/0_CPIS_CDIS_BIS_USTIC_merged_fixed1.dta')\n",
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## export all files to gephi\n",
    "files = [(2009,'total_weight'),(2009,'loans_dep_weight'),(2009,'CDIS_weight'),(2009,'CPIS_weight'),\n",
    "         (2015,'total_weight'),(2015,'loans_dep_weight'),(2015,'CDIS_weight'),(2015,'CPIS_weight')]\n",
    "for x in files:\n",
    "    year,var = x \n",
    "    G = export_gephi(df,year,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
