{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "#import community \n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from seaborn import color_palette, set_style, palplot\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and clean data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## read pre-processed data from stata\n",
    "df = pd.read_stata('../data/0_CPIS_CDIS_BIS_USTIC_merged_fixed1.dta')\n",
    "keep_var = ['countrycode','counterpart_code','country','counterpart','year','CDIS_IAD','CPIS_IAP','loans_dep']\n",
    "df = df[keep_var]                           ## keep only used variables \n",
    "df = df.replace(np.nan,0)                   ## turn na to zero \n",
    "num = df._get_numeric_data()\n",
    "num[num < 0] = 0                            ## turn negative to zero \n",
    "df['total'] = df[['CDIS_IAD','CPIS_IAP','loans_dep']].sum(axis=1)\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create weights for edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mata = ['countrycode','counterpart_code','country','counterpart','year']\n",
    "var_org = ['CDIS_IAD','CPIS_IAP','loans_dep','total']\n",
    "var_sum_out = ['CDIS_Sum_out','CPIS_Sum_out','loans_dep_Sum_out','total_Sum_out']\n",
    "var_sum_in = ['CDIS_Sum_in','CPIS_Sum_in','loans_dep_Sum_in','total_Sum_in']\n",
    "var_weight = ['CDIS_weight','CPIS_weight','loans_dep_weight','total_weight']\n",
    "\n",
    "df[var_sum_out]= df.groupby(['countrycode','year'])[var_org].transform(sum)           ## like stata egen sum \n",
    "df[var_sum_in]= df.groupby(['counterpart_code','year'])[var_org].transform(sum)        ## like stata egen sum \n",
    "df_weight = pd.DataFrame(df[var_org].values / df[var_sum_out].values,columns=[var_weight])\n",
    "df[var_weight] = df_weight                                                        ## create the weight variables \n",
    "mata.extend(var_weight)\n",
    "df = df[mata]\n",
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create centrality measure time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_degree(degree_centrality,G,var,year):\n",
    "    # Find nodes with highest degree, unweighted \n",
    "    k=G.degree(weight=var)                                 ## get the degree centrality for all countries \n",
    "    k = pd.DataFrame(list(k.items()),columns=['country',year])      ## make it into dataframe\n",
    "    k.sort_values(by=year,ascending=0,inplace=True)                 ## sort it \n",
    "    if degree_centrality is None:\n",
    "        degree_centrality = k\n",
    "    else:\n",
    "        degree_centrality = pd.merge(degree_centrality,k,on='country',how='outer')\n",
    "    return degree_centrality\n",
    "\n",
    "def merge_between(between_centrality,G,var,year):\n",
    "    ## betweeness \n",
    "    b = nx.betweenness_centrality(G,weight=var)  # weight='total_weight'\n",
    "    between = pd.DataFrame(list(b.items()),columns=['country',year])      ## make it into dataframe\n",
    "    between.sort_values(by=year,ascending=0,inplace=True)    \n",
    "    if between_centrality is None:\n",
    "        between_centrality = between\n",
    "    else:\n",
    "        between_centrality = pd.merge(between_centrality,between,on='country',how='outer')\n",
    "    return between_centrality\n",
    "\n",
    "def merge_eigenvector(eigenvector_centrality,G,var,year):\n",
    "    ## eigenvector centrality\n",
    "    e = nx.eigenvector_centrality_numpy(G,weight=var)\n",
    "    eigenvector = pd.DataFrame(list(e.items()),columns=['country',year])      ## make it into dataframe\n",
    "    eigenvector.sort_values(by=year,ascending=0,inplace=True)    \n",
    "    if eigenvector_centrality is None:\n",
    "        eigenvector_centrality = eigenvector\n",
    "    else:\n",
    "        eigenvector_centrality = pd.merge(eigenvector_centrality,eigenvector,on ='country',how='outer')\n",
    "    return eigenvector_centrality\n",
    "\n",
    "def merge_closeness(closeness_centrality,G,var,year):\n",
    "    ## closeness centrality\n",
    "    c=nx.closeness_centrality(G,distance =var )\n",
    "    closeness = pd.DataFrame(list(c.items()),columns=['country',year])      ## make it into dataframe\n",
    "    closeness.sort_values(by=year,ascending=0,inplace=True)   \n",
    "    if closeness_centrality is None:\n",
    "        closeness_centrality = closeness\n",
    "    else:\n",
    "        closeness_centrality = pd.merge(closeness_centrality,closeness,on ='country',how='outer')\n",
    "    return closeness_centrality\n",
    "\n",
    "def plot_top_n(centrality,n):\n",
    "    top10 = centrality.ix[0:n]\n",
    "    top10.index = top10.country\n",
    "    top10.drop(labels='country',axis=1,inplace=True)\n",
    "    top10.T.sort_index().plot().legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "def export_to_excel(name):\n",
    "    writer = pd.ExcelWriter(name+'.xlsx', engine='xlsxwriter')\n",
    "    degree_centrality.to_excel(writer, sheet_name='degree')\n",
    "    between_centrality.to_excel(writer, sheet_name='between')\n",
    "    eigenvector_centrality.to_excel(writer, sheet_name='eigenvector')\n",
    "    closeness_centrality.to_excel(writer,sheet_name = 'closeness')\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "### General statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var = 'total_weight'\n",
    "var_dist = 'distance'\n",
    "degree_centrality = None\n",
    "between_centrality = None\n",
    "eigenvector_centrality = None\n",
    "closeness_centrality = None\n",
    "\n",
    "for year in range(2009,2016):\n",
    "    df_graph = df[(df['year']==year) & (df[var]>0)]\n",
    "    df_graph[var_dist] = 1-df_graph[var]\n",
    "    G = nx.from_pandas_dataframe(df_graph, source=\"country\", target=\"counterpart\", edge_attr=[var,var_dist],create_using=nx.DiGraph())\n",
    "    degree_centrality =  merge_degree(degree_centrality,G,var,year)\n",
    "    between_centrality = merge_between(between_centrality,G,var_dist,year)       ## not weighted \n",
    "    eigenvector_centrality = merge_eigenvector(eigenvector_centrality,G,var,year)\n",
    "    closeness_centrality = merge_closeness(closeness_centrality,G,var_dist,year) ## use distance measure\n",
    "    \n",
    "## exoprt to \n",
    "export_to_excel('../result/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_n(eigenvector_centrality,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_top_n(degree_centrality,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_top_n(between_centrality,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_top_n(closeness_centrality,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
