{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import community \n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from seaborn import color_palette, set_style, palplot\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    keep_var = ['countrycode','counterpart_code','country','counterpart','year','CDIS_IAD','CPIS_IAP','loans_dep']\n",
    "    df = df[keep_var]                           ## keep only used variables \n",
    "    df = df.replace(np.nan,0)                   ## turn na to zero \n",
    "    num = df._get_numeric_data()\n",
    "    num[num < 0] = 0                            ## turn negative to zero \n",
    "    df['total'] = df[['CDIS_IAD','CPIS_IAP','loans_dep']].sum(axis=1)\n",
    "\n",
    "    mata = ['countrycode','counterpart_code','country','counterpart','year']\n",
    "    var_org = ['CDIS_IAD','CPIS_IAP','loans_dep','total']\n",
    "    var_sum_out = ['CDIS_Sum_out','CPIS_Sum_out','loans_dep_Sum_out','total_Sum_out']\n",
    "    var_sum_in = ['CDIS_Sum_in','CPIS_Sum_in','loans_dep_Sum_in','total_Sum_in']\n",
    "    var_weight = ['CDIS_weight','CPIS_weight','loans_dep_weight','total_weight']\n",
    "\n",
    "    df[var_sum_out]= df.groupby(['countrycode','year'])[var_org].transform(sum)           ## like stata egen sum \n",
    "    df[var_sum_in]= df.groupby(['counterpart_code','year'])[var_org].transform(sum)        ## like stata egen sum \n",
    "    df_weight = pd.DataFrame((df[var_org].values / df[var_sum_out].values)*100,columns=[var_weight])\n",
    "    df[var_weight] = df_weight                                                        ## create the weight variables \n",
    "    mata.extend(var_weight)\n",
    "    df = df[mata]\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def export_gephi(df,year,var):\n",
    "    ## clean the data first \n",
    "    df_y = df[df['year']==year]\n",
    "    df_y.fillna(0,inplace=True)\n",
    "    df_y = df_y[df_y[var]>0]\n",
    "    G = nx.from_pandas_dataframe(df_y, source=\"country\", target=\"counterpart\", edge_attr=[var],create_using=nx.DiGraph())\n",
    "    #get_hierarchy_cluster(G,var)                                   ## add hierarchy_cluster to node attribute\n",
    "    get_nx_community(G,var)                                        ## add nx community detection to node attribute\n",
    "    get_eigen_centrality(G,var)\n",
    "    get_contagion_data(G,'../result/contagion/country_match.xlsx','Sheet2') ## merge contagion data to G \n",
    "    \n",
    "    nx.write_gexf(G, \"../result/gexf/\"+var+str(year)+\".gexf\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "def get_nx_community(G,var):\n",
    "#algorism: https://sites.google.com/site/findcommunities/\n",
    "#package: http://perso.crans.org/aynaud/communities/\n",
    "    \n",
    "    ## use adj matrix + its invert, so the edge will be the sum of in and out edge weight \n",
    "    node_list = G.nodes()\n",
    "    node_list.sort()\n",
    "    A = nx.to_numpy_matrix(G = G,nodelist=node_list,weight=var)\n",
    "    ud_M = A + A.T \n",
    "    ud_G = nx.from_numpy_matrix(ud_M)\n",
    "    ## relable node to country name \n",
    "    maplist = dict(zip(ud_G.nodes(), node_list))\n",
    "    ud_G = nx.relabel_nodes(ud_G,maplist) \n",
    "    l_community = community.best_partition(ud_G,weight='weight',resolution=1)\n",
    "    nx.set_node_attributes(G, 'nx_community', l_community)\n",
    "    \n",
    "def get_eigen_centrality(G,var):\n",
    "        ## eigenvector centrality\n",
    "    e = nx.eigenvector_centrality_numpy(G,weight=var)\n",
    "    nx.set_node_attributes(G, 'eigenvector_centrality', e) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge contaigion data go G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cont_data(file,sheet):\n",
    "    df_c = pd.read_excel(file,sheet)\n",
    "    df_c['step0'] = (df_c['time step']==0).astype(int)\n",
    "    df_c['step1'] = df_c['time step'].isin([0,1]).astype(int)\n",
    "    df_c['step2'] = df_c['time step'].isin([0,1,2]).astype(int)\n",
    "    df_c['step3'] = df_c['time step'].isin([0,1,2,3]).astype(int)\n",
    "    df_c['step4'] = df_c['time step'].isin([0,1,2,3,4]).astype(int)\n",
    "    df_c['step5'] = df_c['time step'].isin([0,1,2,3,4,5]).astype(int)\n",
    "    df_c['step6'] = df_c['time step'].isin([0,1,2,3,4,5,6]).astype(int)\n",
    "    \n",
    "    return df_c\n",
    "\n",
    "def create_steps(G,df_c):\n",
    "    G_nodes= pd.DataFrame(G.nodes(),columns=['country'])\n",
    "    merge_c=df_c[['country','step0','step1', 'step2','step3', 'step4', 'step5','step6']]\n",
    "    G_merged = pd.merge(G_nodes,merge_c,on='country',how='left')\n",
    "    G_merged.loc[G_merged.country=='United States',['step0','step1', 'step2','step3', 'step4', 'step5','step6']] = 1\n",
    "    G_merged.fillna(0,inplace=True)\n",
    "\n",
    "    return G_merged\n",
    "\n",
    "def merge_steps(G,G_merged):\n",
    "    steps = ['step0','step1', 'step2','step3', 'step4', 'step5','step6']\n",
    "    for s in steps:\n",
    "        con_dict = dict(zip(G_merged['country'],G_merged[s]))\n",
    "        con_dict = {key: int(value) for (key,value) in con_dict.items()}\n",
    "        nx.set_node_attributes(G, s, con_dict)\n",
    "\n",
    "## run all processes  \n",
    "def get_contagion_data(G,file,sheet):\n",
    "    df_c = load_cont_data(file,sheet)\n",
    "    G_merged = create_steps(G,df_c)\n",
    "    merge_steps(G,G_merged)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read pre-processed data from stata\n",
    "df = pd.read_stata('../data/0_CPIS_CDIS_BIS_USTIC_merged_fixed1.dta')\n",
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = export_gephi(df,2015,'total_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## export all files to gephi\n",
    "files = [(2009,'total_weight'),(2009,'loans_dep_weight'),(2009,'CDIS_weight'),(2009,'CPIS_weight'),\n",
    "         (2015,'total_weight'),(2015,'loans_dep_weight'),(2015,'CDIS_weight'),(2015,'CPIS_weight')]\n",
    "for x in files:\n",
    "    year,var = x \n",
    "    G = export_gephi(df,year,var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
