{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MultiContagion as mc\n",
    "import igraph\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import scipy.stats\n",
    "import copy\n",
    "#import powerlaw\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"../data/0_CPIS_CDIS_BIS_USTIC_merged_fixed5.dta\")\n",
    "df = df.sort_index(by=['country'])\n",
    "#by argument to sort_index is deprecated, pls use .sort_values(by=...)\n",
    "df = df.fillna(value = 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df.country == 'China, P.R.: Mainland') & (df.counterpart == 'United States')&(df.year == 2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_inflation = pd.read_csv(\"../data/USA-PCPIE.csv\", index_col=\"Year\")\n",
    "df_inflation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-df_inflation[\"Inflation\"][2009] + df_inflation[\"Inflation\"][2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_inflation = df_inflation.multiply(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_inflation[\"Inflation\"][2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on unities, inflation is in billion dollars and surveys are in million dollars **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] \"Country Name\"                                                                    \n",
    " [2] \"Country Code\"                                                                    \n",
    " [3] \"Counterpart Country Name\"                                                        \n",
    " [4] \"Counterpart Country Code\"                                                        \n",
    " [5] \"Time Period\"                                                                     \n",
    " [6] \"IIP Equity investment asset, millions of USD\"                                    \n",
    " [7] \"IIP Debt instrument asset, millions of USD\"                                      \n",
    " [8] \"IIP Direct investment asset, millions of USD\"                                    \n",
    " [9] \"IIP Direct investment asset between fellow enterprise, millions of USD\"          \n",
    "[10] \"IIP Total Portfolio invertment, Assets, millions of USD\"                         \n",
    "[11] \"IIP Portfolio invertment,Equity and investment fund shares, Assets, millions of \"\n",
    "\n",
    "[12] \"IIP Portfolio invertment,Debt securities, Assets, millions of USD\"               \n",
    "[13] \"BIS loans and deposit claims positions, USD\" <\\br>\n",
    "\n",
    "layers should be: 6, 7, 11, 12 and 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDIS Equity Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The contagion network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_cont_net_from_survey_year_no_isolated(df, data, year):\n",
    "    country = df[\"country\"][ (df[data].notnull()) & (df[data] > 0 ) & (df[\"year\"] == year )]\n",
    "    countercountry = df[\"counterpart\"][ (df[data].notnull()) & (df[data] > 0 ) & (df[\"year\"] == year)  ]\n",
    "    survey = df[data][ (df[data].notnull()) & (df[data] > 0 ) & (df[\"year\"] == year) ]\n",
    "    edges, weight = mc.make_edge_list(countercountry,country, survey)\n",
    "    G = mc.make_graph_from_edge(edges, weight)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Year = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_graphs(y):\n",
    "    \"\"\"graphs with no isolated countries, but then dimensions between matrices dont match\"\"\"\n",
    "    G_cd_equity_15 = make_cont_net_from_survey_year_no_isolated(df, \"CDIS_IADE\", y)\n",
    "    G_cd_debt_15 = make_cont_net_from_survey_year_no_isolated(df, \"CDIS_IADD\", y)\n",
    "    G_cp_equity_15 = make_cont_net_from_survey_year_no_isolated(df, \"CPIS_IAPE\", y)\n",
    "    G_cp_debt_15 = make_cont_net_from_survey_year_no_isolated(df, \"CPIS_IAPD\", y)\n",
    "    G_bis_15 = make_cont_net_from_survey_year_no_isolated(df, \"loans_dep\", y)\n",
    "    G_15_list = [G_cd_equity_15, G_cd_debt_15, G_cp_equity_15, G_cp_debt_15, G_bis_15  ]\n",
    "    G_names = [\"CDIS_equity\", \"CDIS_debt\", \"CPIS_equity\", \"CPIS_debt\", \"BIS\" ]\n",
    "    G_adjacency_15 = []\n",
    "    \n",
    "    for g in G_15_list:\n",
    "        G_adjacency_15.append(np.array((g.get_adjacency(attribute= \"weight\")).data))\n",
    "    \n",
    "    return G_15_list, G_names, G_adjacency_15#, G_agg_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_agg_graph_local(y):\n",
    "    G_cd_equity_15 = mc.make_cont_net_from_survey_year(df, \"CDIS_IADE\", y)\n",
    "    G_cd_debt_15 = mc.make_cont_net_from_survey_year(df, \"CDIS_IADD\", y)\n",
    "    G_cp_equity_15 = mc.make_cont_net_from_survey_year(df, \"CPIS_IAPE\",y)\n",
    "    G_cp_debt_15 = mc.make_cont_net_from_survey_year(df, \"CPIS_IAPD\", y)\n",
    "    G_bis_15 = mc.make_cont_net_from_survey_year(df, \"loans_dep\", y)\n",
    "    G_15_list = [G_cd_equity_15, G_cd_debt_15, G_cp_equity_15, G_cp_debt_15, G_bis_15  ]\n",
    "    G_adjacency_15 = []\n",
    "    for g in G_15_list:\n",
    "        G_adjacency_15.append(np.array((g.get_adjacency(attribute= \"weight\")).data))\n",
    "\n",
    "    AM_agg_2015 = G_adjacency_15[0] + G_adjacency_15[1] + G_adjacency_15[2] + G_adjacency_15[3] + G_adjacency_15[4]\n",
    "    G_agg_2015 = igraph.Graph.Weighted_Adjacency(AM_agg_2015.tolist(), attr= \"weight\")\n",
    "    \n",
    "    return G_agg_2015, AM_agg_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_list, G_nm, G_adj = make_graphs(Year)\n",
    "G_agg, G_adj_agg = make_agg_graph_local(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(G_adj[2][0]) # we excluded some nodes\n",
    "len( G_adj_agg), len(G_adj_agg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_survey_names = {0: \"CDIS-equity\", 1: \"CDIS-debt\",2: \"CPIS-equity\",3: \"CPIS-debt\",4: \"BIS\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = \"AM4_no_isolated\"\n",
    "for y in range(2008,2016):\n",
    "    G_list, G_nm, G_adj = make_graphs(y)\n",
    "    for i in range(5):\n",
    "        survey_name = dict_survey_names[i]\n",
    "        np.savetxt(\"../data/adj/\"+name+survey_name+str(y)+\".csv\", G_adj[i], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_data2 = np.genfromtxt('../data/adj/AM4_no_isolatedCDIS-equity2015.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_adj[0] == my_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save basic measurments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_basic_measurements(y, G_list_plus_agg, G_nm_plus_agg):\n",
    "    f = open(\"csv_files/basic_masurements_\"+str(Year) +\".csv\", \"w\")\n",
    "    f.write(\",diameter,density,average path length,global clustering,average clustering (unweighted),average clustering,sum of weights\\n\")\n",
    "    n = len(G_nm_plus_agg)\n",
    "    for i in range(n):\n",
    "        f.write(G_nm_plus_agg[i] + \",\")\n",
    "        g = G_list_plus_agg[i]\n",
    "        weights = np.array(copy.deepcopy(g.es[\"weight\"]))\n",
    "        f.write(str( round(g.diameter(), 2) ) + \",\")\n",
    "        f.write(str( round(g.density(), 2) ) + \",\")\n",
    "        f.write(str( round(g.average_path_length(), 2) ) + \",\")\n",
    "        f.write(str( round(g.transitivity_undirected(), 2) ) + \",\")\n",
    "        f.write(str( round(np.mean(g.transitivity_local_undirected( mode = \"zero\")), 2) ) + \",\")\n",
    "        f.write(str( round(np.mean(g.transitivity_local_undirected(weights = g.es[\"weight\"],  mode = \"zero\" )), 2) ) + \",\")\n",
    "        f.write(str( round(sum(weights)) ) + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for Year in [2008 + i for i in range(8)]:\n",
    "    print Year\n",
    "    G_list, G_nm, G_adj = make_graphs(Year)\n",
    "    G_agg = make_agg_graph_local(Year)\n",
    "    G_list_plus_agg = G_list + [G_agg]\n",
    "    G_nm_plus_agg = G_nm + [\"Aggregated\"]\n",
    "    save_basic_measurements(Year, G_list_plus_agg, G_nm_plus_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between networks of different years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we need matrices with all the nodes, even the ones that were not reported in that year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Year = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"../data/0_CPIS_CDIS_BIS_USTIC_merged_fixed5.dta\")\n",
    "df = df.sort_index(by=['country'])\n",
    "df = df.fillna(value = 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_cont_net_from_survey_year_all_countries(df, data, year):\n",
    "    all_years = [i for i in range(2008,2016)]\n",
    "    all_years.remove(year)\n",
    "    #print all_years\n",
    "    country = df[\"country\"]\n",
    "    countercountry = df[\"counterpart\"]\n",
    "    DF = df.copy()\n",
    "    DF.ix[df.year.isin(all_years), data] = 0\n",
    "    survey = DF[data]\n",
    "    edges, weight = mc.make_edge_list(countercountry,country, survey)\n",
    "    for i in range(len(weight)):\n",
    "        if weight[i] < 0:\n",
    "            weight[i] = 0\n",
    "    G = mc.make_graph_from_edge(edges, weight)\n",
    "   \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_graphs_allnodes(y, norm = False):\n",
    "    '''Dimensions of matrices match even between years'''\n",
    "    df_copy = copy.deepcopy(df)\n",
    "    if norm == True:\n",
    "        df_copy[['CDIS_IADE', 'CDIS_IADE', 'CPIS_IAPE', 'CPIS_IAPD', 'loans_dep' ] ] *= 1./df_inflation[\"Inflation\"][y]\n",
    "    G_cd_equity_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CDIS_IADE\", y)\n",
    "    G_cd_debt_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CDIS_IADD\", y)\n",
    "    G_cp_equity_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CPIS_IAPE\", y)\n",
    "    G_cp_debt_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CPIS_IAPD\", y)\n",
    "    G_bis_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"loans_dep\", y)\n",
    "    G_15_list = [G_cd_equity_15, G_cd_debt_15, G_cp_equity_15, G_cp_debt_15, G_bis_15  ]\n",
    "    G_names = [\"CDIS_equity\", \"CDIS_debt\", \"CPIS_equity\", \"CPIS_debt\", \"BIS\" ]\n",
    "    G_adjacency_15 = []\n",
    "    \n",
    "    for g in G_15_list:\n",
    "        G_adjacency_15.append(np.array((g.get_adjacency(attribute= \"weight\")).data))\n",
    "    #print G_15_list[0].vs[\"name\"][0]\n",
    "    return G_15_list, G_names, G_adjacency_15#, G_agg_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_agg_graph(y, norm = False):\n",
    "    df_copy = copy.deepcopy(df)\n",
    "    if norm == True:\n",
    "        df_copy[['CDIS_IADE', 'CDIS_IADE', 'CPIS_IAPE', 'CPIS_IAPD', 'loans_dep' ] ] *= 1./df_inflation[\"Inflation\"][y]\n",
    "    G_cd_equity_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CDIS_IADE\", y)\n",
    "    G_cd_debt_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CDIS_IADD\", y)\n",
    "    G_cp_equity_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CPIS_IAPE\",y)\n",
    "    G_cp_debt_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"CPIS_IAPD\", y)\n",
    "    G_bis_15 = make_cont_net_from_survey_year_all_countries(df_copy, \"loans_dep\", y)\n",
    "    G_15_list = [G_cd_equity_15, G_cd_debt_15, G_cp_equity_15, G_cp_debt_15, G_bis_15  ]\n",
    "    G_adjacency_15 = []\n",
    "    for g in G_15_list:\n",
    "        G_adjacency_15.append(np.array((g.get_adjacency(attribute= \"weight\")).data))\n",
    "\n",
    "    AM_agg_2015 = G_adjacency_15[0] + G_adjacency_15[1] + G_adjacency_15[2] + G_adjacency_15[3] + G_adjacency_15[4]\n",
    "    G_agg_2015 = igraph.Graph.Weighted_Adjacency(AM_agg_2015.tolist(), attr= \"weight\")\n",
    "    \n",
    "    return G_agg_2015, AM_agg_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_survey_names = {0: \"CDIS-equity\", 1: \"CDIS-debt\",2: \"CPIS-equity\",3: \"CPIS-debt\",4: \"BIS\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = \"AM4_all_nodes\"\n",
    "for y in range(2008,2016):\n",
    "    G_list, G_nm, G_adj = make_graphs_allnodes(y, norm = False)\n",
    "    for i in range(5):\n",
    "        survey_name = dict_survey_names[i]\n",
    "        np.savetxt(\"../data/adj/\"+name+survey_name+str(y)+\".csv\", G_adj[i], delimiter=\",\")\n",
    "        print(name+survey_name+str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = \"AM4_all_nodes_aggregate\"\n",
    "for y in range(2008,2016):\n",
    "    Ga_list, G_adj = make_agg_graph(y, norm = False)\n",
    "    np.savetxt(\"../data/adj/\"+name+str(y)+\".csv\", G_adj, delimiter=\",\")\n",
    "    print(name+str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_names = G_list[0].vs[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len( G_list[3].vs[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_names = G_list[0].vs[\"name\"]\n",
    "f = open(\"../data/adj/\"+\"all_country_name4\"+\".csv\", \"w\")\n",
    "for i in all_names:\n",
    "    f.write(i+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### HeatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For aggregated network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_Ag_ADJ = []\n",
    "G_Ag_NAMES = []\n",
    "G_Ag_G = []\n",
    "for y in range(2008,2016):\n",
    "    a, c = make_agg_graph(y,norm = True)\n",
    "    G_Ag_ADJ.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_matrix(A):\n",
    "    norm = sum(sum(A))\n",
    "    #print norm\n",
    "    return A/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(G_Ag_ADJ)#[2] #== G_ADJ[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_agg_NORM = []\n",
    "for am in G_Ag_ADJ:\n",
    "    A_agg_NORM.append(norm_matrix(am) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_agg, std_agg = np.mean(difference_single_mat(A_agg_NORM[0] , A_agg_NORM[1])), np.std(difference_single_mat(A_agg_NORM[0] , A_agg_NORM[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = difference_single_mat(A_agg_NORM[0] , A_agg_NORM[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = filter(lambda a: a != 0, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(t), np.std(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_agg, std_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_agg, std_agg = np.mean(difference_mat(A_NORM[0][1] , A_NORM[1][1])), np.std(difference_mat(A_NORM[0][1] , A_NORM[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_agg, std_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_single_mat(A_agg_NORM[-2] , A_agg_NORM[-1])[11] #== difference_mat(A_NORM[0][1] , A_NORM[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def difference_mat(A, B):\n",
    "    l = len(A[0])\n",
    "    dif = []\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            dif.append( abs( A[i, j] - B[i, j]))\n",
    "    return dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[-2][0] , A_NORM[0][0])[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[-2][1] , A_NORM[0][1])[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[-2][2] , A_NORM[0][2])[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[-2][3] , A_NORM[0][3])[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[-2][-1] , A_NORM[-1][-1])[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[0][1] , A_NORM[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[0][0] , A_NORM[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_single_mat(A_agg_NORM[0] , A_agg_NORM[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_agg_NORM[1][-2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_NORM[1][1][-2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def difference_single_mat(A, B):\n",
    "    l = len(A)\n",
    "    dif = []\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            dif.append(abs( A[i, j] - B[i, j]))\n",
    "    return dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dif = []\n",
    "for y1 in range(2016-2009):\n",
    "    dif.append([])\n",
    "    for y2 in range(2016-2009):\n",
    "        dif[y1].append(sum(difference_single_mat(A_agg_NORM[y1 + 1] , A_agg_NORM[y2 + 1])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = [str(y) for y in range(2009,2016)]#'abcdefghij'\n",
    "\n",
    "for axis in [ax.xaxis, ax.yaxis]:\n",
    "    axis.set(ticks=np.arange(0.5, len(labels)), ticklabels=labels)\n",
    "\n",
    "plt.pcolor(dif,  vmin=0, vmax=0.5)\n",
    "plt.title(\"Aggregate, diference between years\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"fig/TemporalDiferenceNorm-Agg-eq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dif == DIF[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_ADJ = []\n",
    "G_NAMES = []\n",
    "G_G = []\n",
    "for y in range(2008,2016):\n",
    "    a, b , c = make_graphs_allnodes(y)\n",
    "    G_ADJ.append(c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_NORM = []\n",
    "for g_year in G_ADJ:\n",
    "    A_NORM.append([norm_matrix(am) for am in g_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def difference_mat(A, B):\n",
    "    l = len(A[0])\n",
    "    dif = 0\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            dif += abs( A[i, j] - B[i, j])\n",
    "    return dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "difference_mat(A_NORM[-1][2] , A_NORM[-2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIF = []\n",
    "for i in range(5):\n",
    "    dif = []\n",
    "    for y1 in range(2016-2009):\n",
    "        dif.append([])\n",
    "        for y2 in range(2016-2009):\n",
    "            dif[y1].append(difference_mat(A_NORM[y1 + 1][i] , A_NORM[y2 + 1][i]))\n",
    "    DIF.append(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = [str(y) for y in range(2009,2016)]#'abcdefghij'\n",
    "\n",
    "for axis in [ax.xaxis, ax.yaxis]:\n",
    "    axis.set(ticks=np.arange(0.5, len(labels)), ticklabels=labels)\n",
    "\n",
    "plt.pcolor(DIF[0],  vmin=0, vmax=0.5)\n",
    "plt.title(\"CDIS - equity, diference between years\")\n",
    "plt.colorbar()\n",
    "#plt.savefig(\"fig/TemporalDiferenceNorm-CDIS-eq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = [str(y) for y in range(2009,2016)]#'abcdefghij'\n",
    "\n",
    "for axis in [ax.xaxis, ax.yaxis]:\n",
    "    axis.set(ticks=np.arange(0.5, len(labels)), ticklabels=labels)\n",
    "\n",
    "plt.pcolor(DIF[1],  vmin=0, vmax=0.5)\n",
    "plt.savefig(\"fig/TemporalDiference-CDIS-de.png\")\n",
    "plt.title(\"CDIS - debt, diference between years\")\n",
    "plt.colorbar()\n",
    "#plt.savefig(\"fig/TemporalDiferenceNorm-CDIS-de.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = [str(y) for y in range(2009,2016)]#'abcdefghij'\n",
    "\n",
    "for axis in [ax.xaxis, ax.yaxis]:\n",
    "    axis.set(ticks=np.arange(0.5, len(labels)), ticklabels=labels)\n",
    "\n",
    "plt.pcolor(DIF[2],  vmin=0, vmax=0.5)\n",
    "plt.title(\"CPIS - equity, diference between years\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"fig/TemporalDiferenceNorm-CPIS-eq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = [str(y) for y in range(2009,2016)]#'abcdefghij'\n",
    "\n",
    "for axis in [ax.xaxis, ax.yaxis]:\n",
    "    axis.set(ticks=np.arange(0.5, len(labels)), ticklabels=labels)\n",
    "\n",
    "plt.pcolor(DIF[3],  vmin=0, vmax=0.5)\n",
    "plt.title(\"CPIS - debt, diference between years\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"fig/TemporalDiferenceNorm-CPIS-de.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "labels = [str(y) for y in range(2009,2016)]#'abcdefghij'\n",
    "\n",
    "for axis in [ax.xaxis, ax.yaxis]:\n",
    "    axis.set(ticks=np.arange(0.5, len(labels)), ticklabels=labels)\n",
    "\n",
    "plt.pcolor(DIF[4],  vmin=0, vmax=0.5)\n",
    "plt.title(\"BIS, diference between years\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"fig/TemporalDiferenceNorm-BIS.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deficit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_deficit(G):\n",
    "    in_flow = np.array(G.strength(weights= G.es[\"weight\"], mode = \"IN\"))\n",
    "    out_flow = np.array(G.strength(weights= G.es[\"weight\"], mode = \"OUT\"))\n",
    "    return in_flow - out_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defi = []\n",
    "#for i in range(len(G_names)):\n",
    "#    nm = G_names[i]\n",
    "#    g = G_15_list[i]\n",
    "#    deficit = get_deficit(g)\n",
    "#    node_names = np.array(copy.deepcopy(g.vs[\"name\"]))\n",
    "#    num_nodes = [i for i in range(len(node_names))]\n",
    "#    plt.figure(figsize=(36,4))\n",
    "#    #defi.append(deficit)\n",
    "#    inds = deficit.argsort()\n",
    "#    sort_names = node_names[inds]\n",
    "#    deficit_sort = deficit[inds]\n",
    "#    plt.figure(figsize=(30,4))\n",
    "#    plt.plot(num_nodes, deficit_sort, \".\")\n",
    "#    plt.xticks(num_nodes, sort_names ,rotation='vertical')\n",
    "#    plt.yscale('symlog')\n",
    "#    plt.ylabel(\"Lendings - borrowings\", fontsize = 20)\n",
    "#    plt.title(nm+ \" deficit 2015\", fontsize = 30)\n",
    "#    plt.xlim([-1, len(num_nodes)])\n",
    "#    plt.savefig(\"fig/deficit\"+ nm +str(y) +\".png\", bbox_inches = \"tight\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort_names[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between in-out strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(G_names)):\n",
    "    nm = G_names[i]\n",
    "    g = G_15_list[i]\n",
    "    in_str = g.strength(weights= g.es[\"weight\"], mode = \"IN\")\n",
    "    out_str = g.strength(weights= g.es[\"weight\"], mode = \"OUT\")\n",
    "    print np.polyfit(in_str, out_str, 1)\n",
    "    print scipy.stats.pearsonr(in_str, out_str)\n",
    "    plt.plot(in_str, out_str, \".\" ) \n",
    "    plt.plot(in_str, in_str, label = \"Identity \\n line\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel(\"out-strength\", fontsize = 12)\n",
    "    plt.xlabel(\"in-strength\", fontsize = 12)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(nm+ \" In-Out strength relation\"+str(y), fontsize = 15)\n",
    "    plt.savefig(\"fig/In-Out\"+ nm + str(y)+\".png\", bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(G_cd_equity.strength(weights=G_cd_equity.es[\"weight\"], mode = \"IN\"), G_cd_equity.strength(weights=G_cd_equity.es[\"weight\"], mode = \"OUT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strength distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(G_names)):\n",
    "    nm = G_names[i]\n",
    "    g = G_15_list[i]\n",
    "    strength = g.strength(weights= g.es[\"weight\"])\n",
    "    hist, bins = np.histogram(strength, bins = np.logspace(0.1, np.log(max(strength)), 50 ) )\n",
    "    plt.plot(bins[:-1], hist, \".-\", label = nm)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel(\"Frequency\", fontsize = 12)\n",
    "    plt.xlabel(\"Strength\", fontsize = 12)\n",
    "    plt.xlim([0.1, 1e10])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title( \" Degree distribution \"+ str(y), fontsize = 15)\n",
    "plt.savefig(\"fig/DegreeDist\"+ \"All\" + str(y) +\".png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(G_names)):\n",
    "    nm = G_names[i]\n",
    "    g = G_15_list[i]\n",
    "    strength = g.strength(weights= g.es[\"weight\"])\n",
    "    hist, bins = np.histogram(strength, bins = np.logspace(0.1, np.log(max(strength)), 50 ) )\n",
    "    plt.plot(bins[:-1], hist, \".\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel(\"Frequency\", fontsize = 12)\n",
    "    plt.xlabel(\"Strength\", fontsize = 12)\n",
    "    plt.xlim([0.1, 1e10])\n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(nm+ \" Degree distribution 2015\", fontsize = 15)\n",
    "    #plt.savefig(\"fig/DegreeDist\"+ nm + \".png\", bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(G_names)):\n",
    "    nm = G_names[i]\n",
    "    g = G_15_list[i]\n",
    "    weights = g.es[\"weight\"]\n",
    "    hist, bins = np.histogram(weights, bins = np.logspace(0.1, np.log(max(strength)), 100 ) )\n",
    "    \n",
    "    #results = powerlaw.Fit(hist) \n",
    "    #print results.power_law.alpha \n",
    "    #print results.power_law.xmin \n",
    "    #R, p = results.distribution_compare('power_law', 'lognormal') \n",
    "    #print R, p\n",
    "    plt.plot(bins[:-1], hist, \".-\", label = nm)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xlim([0.1, 1e8])\n",
    "    plt.ylabel(\"Frequency\", fontsize = 12)\n",
    "    plt.xlabel(\"weight\", fontsize = 12)\n",
    "    plt.xlim()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title( \" Weight distribution \"+ str(y), fontsize = 15)\n",
    "plt.savefig(\"fig/WeightDist\"+ \"All\"+str(y) +\".png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(G_names)):\n",
    "    nm = G_names[i]\n",
    "    g = G_15_list[i]\n",
    "    weights = g.es[\"weight\"]\n",
    "    hist, bins = np.histogram(weights, bins = np.logspace(0.1, np.log(max(strength)), 100 ) )\n",
    "    \n",
    "    results = powerlaw.Fit(hist) \n",
    "    print results.power_law.alpha \n",
    "    print results.power_law.xmin \n",
    "    R, p = results.distribution_compare('power_law', 'lognormal') \n",
    "    print R, p\n",
    "    plt.plot(bins[:-1], hist, \".\")\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xlim([0.1, 1e8])\n",
    "    plt.ylabel(\"Frequency\", fontsize = 12)\n",
    "    plt.xlabel(\"weight\", fontsize = 12)\n",
    "    plt.xlim()\n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(nm+ \" Weight distribution 2015\", fontsize = 15)\n",
    "    plt.savefig(\"fig/WeightDist\"+ nm +\".png\", bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"csv_files/PageRank_\"+str(y)+\".csv\", \"w\")\n",
    "S_names = []\n",
    "for i in range(len(G_names)):\n",
    "    \n",
    "    nm = G_names[i]\n",
    "    f.write(nm + \",\")\n",
    "    g = G_15_list[i]\n",
    "    pagerank = np.array(g.pagerank(directed = True, weights = g.es[\"weight\"]))\n",
    "    node_names = np.array( copy.deepcopy( g.vs[\"name\"] ) )\n",
    "    inds = pagerank.argsort()\n",
    "    sort_names = node_names[inds]\n",
    "    S_names.append(sort_names)\n",
    "    pagerank_sort = pagerank[inds]\n",
    "    s = list(sort_names)\n",
    "    while len(s) > 0:\n",
    "        c = s.pop()\n",
    "        f.write(c + \",\")\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kendall tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scipy.stats.kendalltau(np.array([\"A\", \"B\", \"C\", \"D\"]), np.array([\"A\", \"B\", \"D\", \"C\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "All_nodes_name_list = []\n",
    "for alf in range(len(G_names)):\n",
    "\n",
    "    g = G_15_list[alf]\n",
    "    names = g.vs[\"name\"]\n",
    "    for nm in names:\n",
    "        if nm not in All_nodes_name_list:\n",
    "            All_nodes_name_list.append(nm)\n",
    "            \n",
    "All_nodes_name_list;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "All_node_layer_name_dict = {}\n",
    "All_node_layer_strength_dict = {}\n",
    "for alf in range(len(G_names)):\n",
    "    g = g = G_15_list[alf]\n",
    "    names = g.vs[\"name\"]\n",
    "    size_layer = len(names)\n",
    "    for i in range(size_layer):\n",
    "        All_node_layer_name_dict[(alf, i)] = names[i]\n",
    "        All_node_layer_strength_dict[(alf, i)]= g.strength(weights= g.es[\"weight\"])[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.vs[\"name\"].index(\"Afghanistan, Islamic Republic of\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_node_layer_name_dict[(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_nodes_overlap_dict = {}\n",
    "All_nodes_overlap_list = []\n",
    "for k in range(len(All_nodes_name_list)):\n",
    "    name = All_nodes_name_list[k]\n",
    "    overlap = 0\n",
    "    \n",
    "    for alf in range(len(G_names)):\n",
    "        g = g = G_15_list[alf]\n",
    "        try:\n",
    "            i = g.vs[\"name\"].index(name)\n",
    "            overlap += g.strength(weights= g.es[\"weight\"])[i]\n",
    "        except:\n",
    "            #print alf, name  \n",
    "            pass\n",
    "    All_nodes_overlap_list.append(overlap)\n",
    "    All_nodes_overlap_dict[name] = overlap\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlap_mean, overlap_std = np.mean(All_nodes_overlap_list), np.std(All_nodes_overlap_list)\n",
    "print overlap_mean, overlap_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "All_nodes_zscore_dict = {}\n",
    "All_nodes_zscore_list = []\n",
    "for k in range(len(All_nodes_name_list)):\n",
    "    zscore = (All_nodes_overlap_list[k] - overlap_mean)/overlap_std\n",
    "    All_nodes_zscore_list.append(zscore)\n",
    "    \n",
    "    name = All_nodes_name_list[k]\n",
    "    All_nodes_zscore_dict[name] = zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for z in All_nodes_zscore_dict:\n",
    "    if All_nodes_zscore_dict[z] > 1:\n",
    "        print z, \",\" ,All_nodes_zscore_dict[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_node_layer_strength_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def participation_coef(M,s_vec, o):\n",
    "    '''Take into aacount only the layers in which it is part of'''\n",
    "    val = 0\n",
    "    if len(s_vec) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(len(s_vec)):\n",
    "            val += (s_vec[i]/float(o))**2\n",
    "        return (float(M)/ (M - 1))*(1 - val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_nodes_partcoef_dict = {}\n",
    "All_nodes_partcoef_list = []\n",
    "for k in range(len(All_nodes_name_list)):\n",
    "    name = All_nodes_name_list[k]\n",
    "    strength_lay_vec = []\n",
    "    name = All_nodes_name_list[k]\n",
    "    for alf in range(len(G_names)):\n",
    "        g = g = G_15_list[alf]\n",
    "        try:\n",
    "            i = g.vs[\"name\"].index(name)\n",
    "            strength_lay_vec.append(All_node_layer_strength_dict[(alf, i)])\n",
    "            \n",
    "        except:\n",
    "            #print  name in g.vs[\"name\"]\n",
    "            print alf, name  \n",
    "            pass\n",
    "    part_coef = participation_coef(len(G_names), strength_lay_vec, All_nodes_overlap_list[k] )\n",
    "    All_nodes_partcoef_list.append(part_coef)\n",
    "    All_nodes_partcoef_dict[name] = part_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(All_nodes_partcoef_list), np.std(All_nodes_partcoef_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in All_nodes_partcoef_dict:\n",
    "    if All_nodes_partcoef_dict[p] > 0.90:\n",
    "        print p, \",\" ,All_nodes_partcoef_dict[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_nodes_overlap_dict['Afghanistan, Islamic Republic of']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
